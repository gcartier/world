;;;===============
;;;  WorldScheme
;;;===============
;;;
;;;; World UDP BBR
;;;
;;;  The Initial Developer of the Original Code is Guillaume Cartier.
;;;  Portions created by the Initial Developer are Copyright (C) 2012-2018
;;;  the Initial Developer. All Rights Reserved.
;;;
;;;  Contributor(s):
;;;    Barbara Samson


;;  Bottleneck Bandwidth and RTT (BBR) congestion control
;;
;;  BBR congestion control computes the sending rate based on the delivery
;;  rate (throughput) estimated from ACKs. In a nutshell:
;;
;;    On each ACK, update our model of the network path:
;;       bottleneck_bandwidth = windowed_max(delivered / elapsed, 10 round trips)
;;       min_rtt = windowed_min(rtt, 10 seconds)
;;    pacing_rate = pacing_gain * bottleneck_bandwidth
;;    cwnd = max(cwnd_gain * bottleneck_bandwidth * min_rtt, 4)
;;
;;  The core algorithm does not react directly to packet losses or delays,
;;  although BBR may adjust the size of next send per ACK when loss is
;;  observed, or adjust the sending rate if it estimates there is a
;;  traffic policer, in order to keep the drop rate reasonable.
;;
;;  Here is a state transition diagram for BBR:
;;
;;              |
;;              V
;;     +---> STARTUP  ----+
;;     |        |         |
;;     |        V         |
;;     |      DRAIN   ----+
;;     |        |         |
;;     |        V         |
;;     +---> PROBE_BW ----+
;;     |      ^    |      |
;;     |      |    |      |
;;     |      +----+      |
;;     |                  |
;;     +---- PROBE_RTT <--+
;;
;;  A BBR flow starts in STARTUP, and ramps up its sending rate quickly.
;;  When it estimates the pipe is full, it enters DRAIN to drain the queue.
;;  In steady state a BBR flow only uses PROBE_BW and PROBE_RTT.
;;  A long-lived BBR flow spends the vast majority of its time remaining
;;  (repeatedly) in PROBE_BW, fully probing and utilizing the pipe's bandwidth
;;  in a fair manner, with a small, bounded queue. *If* a flow has been
;;  continuously sending for the entire min_rtt window, and hasn't seen an RTT
;;  sample that matches or decreases its min_rtt estimate for 10 seconds, then
;;  it briefly enters PROBE_RTT to cut inflight to a minimum value to re-probe
;;  the path's two-way propagation delay (min_rtt). When exiting PROBE_RTT, if
;;  we estimated that we reached the full bw of the pipe then we enter PROBE_BW;
;;  otherwise we enter STARTUP to try to fill the pipe.
;;
;;  BBR is described in detail in:
;;    "BBR: Congestion-Based Congestion Control",
;;    Neal Cardwell, Yuchung Cheng, C. Stephen Gunn, Soheil Hassas Yeganeh,
;;    Van Jacobson. ACM Queue, Vol. 14 No. 5, September-October 2016.
;;
;;  There is a public e-mail list for discussing BBR development and testing:
;;    https://groups.google.com/forum/#!forum/bbr-dev
;;
;;  NOTE: BBR might be used with the fq qdisc ("man tc-fq") with pacing enabled,
;;  otherwise TCP stack falls back to an internal pacing using one high
;;  resolution timer per TCP socket and may use more resources.


;; bbr
;; wscale:6,7
;; rto:232
;; rtt:31.752/1.501
;; ato:52
;; mss:1408
;; pmtu:1460
;; rcvmss:1408
;; advmss:1408
;; cwnd:116
;; ssthresh:82
;; bytes_acked:43905681
;; bytes_received:15917
;; segs_out:31322
;; segs_in:2402
;; data_segs_out:31311
;; data_segs_in:354
;; bbr:
;;   (bw:36.6Mbps,
;;    mrtt:8.216,
;;    pacing_gain:1,
;;    cwnd_gain:2)
;; send 41.2Mbps
;; lastrcv:16
;; pacing_rate 36.2Mbps
;; delivery_rate 33.9Mbps
;; busy:10968ms
;; rwnd_limited:8ms(0.1%)
;; unacked:88
;; retrans:0/31
;; rcv_space:14200
;; rcv_ssthresh:64116
;; notsent:1876088
;; minrtt:8.216


;;  Adapted from linux tcp_bbr
(module world.bbr jazz


;; TODO
;; - review the various div I defined as /
;; - what all is working remove the
;;   continuation-capture return


;; LEXICON
;;   BtlBw    : Bottleneck Bandwidth
;;   cwnd     : Congestion Window
;;   BDP      : Bandwidth Delay Product
;;   RTprop   : estimate of the round-trip propagation delay
;;   SKB      : socket buffer
;;   EDT      : earliest departure time
;;   SACK     : Selective Acknowledgment
;;   ssthresh : slow start threshold
;;   ECN      : Explicit Congestion Notification
;;   GSO      : Generic Segment Offload


(import (jazz.debuggee)
        (jazz.math))


(proclaim (generate))


(definition show
  debug)


(definition READ_ONCE
  identity)


(constant tilde0U
  -1)

(constant tilde1U
  -2)


(definition before
  <)

(definition after
  >)


;; jiffies (a low-resolution clock)
;; mstamp (a microsecond-resolution clock)


(constant USEC_PER_SEC 1000000)
(constant USEC_PER_MSEC 1000)
(constant NSEC_PER_USEC 1000)


;; not sure
(constant HZ 1000)
(definition (tcp_jiffies32) (fxround (* (current-monotonic) 1000.)))
(definition (msecs_to_jiffies ms) ms)


;; todo
(definition prandom_u32_max random-integer)
(definition div64_long (lambda (x y) (fxround (/ x y))))
(definition div_u64 (lambda (x y) (fxround (/ x y))))
(definition do_div (lambda (x y) (fxround (/ x y))))


;; todo
(constant TCP_INIT_CWND 10)
(constant TCP_INFINITE_SSTHRESH #x7fffffff)
(constant MAX_TCP_HEADER 272)
(constant GSO_MAX_SIZE 65536)


;;  Sender's congestion state indicating normal or abnormal situations
;;  in the last round of packets sent. The state is driven by the ACK
;;  information and timer events.

;; Nothing bad has been observed recently.
;; No apparent reordering, packet loss, or ECN marks.
(constant TCP_CA_Open 0)

;; The sender enters disordered state when it has received DUPACKs or
;; SACKs in the last round of packets sent. This could be due to packet
;; loss or reordering but needs further information to confirm packets
;; have been lost.
(constant TCP_CA_Disorder 1)

;; The sender enters Congestion Window Reduction (CWR) state when it
;; has received ACKs with ECN-ECE marks, or has experienced congestion
;; or packet discard on the sender host (e.g. qdisc).
(constant TCP_CA_CWR 2)

;; The sender is in fast recovery and retransmitting lost packets,
;; typically triggered by ACK events.
(constant TCP_CA_Recovery 3)

;; The sender is in loss recovery triggered by retransmission timeout.
(constant TCP_CA_Loss 4)


(definition (inet_csk->icsk_ca_state) TCP_CA_Open)


;; RFC793 variables by their proper names
;; u32	mss_cache          ;; Cached effective mss, not including SACKS
;; u64	tcp_wstamp_ns      ;; departure time for next sent data packet
;; u64	tcp_clock_cache    ;; cache last tcp_clock_ns() (see tcp_mstamp_refresh())

;; RTT measurement
;; u64	tcp_mstamp         ;; most recent packet received/sent
;; u32	srtt_us            ;; smoothed round trip time << 3 in usecs

;;  Slow start and congestion control (see also Nagle, and Karn & Partridge)
;; u32	snd_ssthresh       ;; Slow start size threshold
;; u32	snd_cwnd           ;; Sending congestion window
;; u32	snd_cwnd_clamp     ;; Do not allow snd_cwnd to grow above this
;; u32	lost               ;; Total data packets lost incl. rexmits
;; u32	app_limited        ;; limited until "delivered" reaches this val
;; u32	delivered          ;; Total data packets delivered incl. rexmits
;; u64	delivered_mstamp   ;; time we reached "delivered"


(definition (tcp_packets_in_flight) 10)
(definition (tcp_stamp_us_delta x y) 0)
(definition (tcp_min_rtt) (inexact->exact (* .014 USEC_PER_SEC)))


(definition %tcp_sk->snd_cwnd%
  116)

(definition %tcp_sk->snd_ssthresh%
  10)

(definition %tcp_sk->app_limited%
  0)

(definition (tcp_sk->snd_cwnd) %tcp_sk->snd_cwnd%)         (definition (set-tcp_sk->snd_cwnd value) (show 'snd_cwnd value) (set! %tcp_sk->snd_cwnd% value))
(definition (tcp_sk->snd_cwnd_clamp) 20)
(definition (tcp_sk->snd_ssthresh) %tcp_sk->snd_ssthresh%) (definition (set-tcp_sk->snd_ssthresh value) (show 'snd_ssthresh value) (set! %tcp_sk->snd_ssthresh% value))
(definition (tcp_sk->delivered) 5)
(definition (tcp_sk->delivered_mstamp) 0)
(definition (tcp_sk->lost) 0)
(definition (tcp_sk->tcp_clock_cache) 0)
(definition (tcp_sk->tcp_wstamp_ns) 0)
(definition (tcp_sk->srtt_us) (inexact->exact (* .014 USEC_PER_SEC)))
(definition (tcp_sk->mss_cache) 1460) ;; MSS = MTU - 40
(definition (tcp_sk->app_limited) %tcp_sk->app_limited%)   (definition (set-tcp_sk->app_limited value) (show 'app_limited value) (set! %tcp_sk->app_limited% value))
(definition (tcp_sk->tcp_mstamp) 0)


(definition %sk->sk_pacing_rate%
  1)

(definition (sk->sk_pacing_rate) %sk->sk_pacing_rate%)     (definition (set-sk->sk_pacing_rate value) (show 'pacing_rate value) (set! %sk->sk_pacing_rate% value))
(definition (sk->sk_max_pacing_rate) 100)
(definition (sk->sk_pacing_status) 0)
(definition (sk->sk_pacing_shift) 0)


(class Rate-Sample extends Object)


;;  A rate sample measures the number of (original/retransmitted) data
;;  packets delivered "delivered" over an interval of time "interval_us".
;;  The tcp_rate.c code fills in the rate sample, and congestion
;;  control modules that define a cong_control function to run at the end
;;  of ACK processing can optionally chose to consult this sample when
;;  setting cwnd and pacing rate.
;;  A sample is invalid if "delivered" or "interval_us" is negative.
(definition (rate_sample->losses rs) 0)            ;; number of packets marked lost upon ACK
(definition (rate_sample->rtt_us rs)
  (inexact->exact (* .014 USEC_PER_SEC)))          ;; RTT of last (S)ACKed packet (or -1)
(definition (rate_sample->is_ack_delayed rs) 0)    ;; is this (likely) a delayed ACK?
(definition (rate_sample->acked_sacked rs) 0)      ;; number of packets newly (S)ACKed upon ACK
(definition (rate_sample->prior_delivered rs) 0)   ;; tp->delivered at "prior_mstamp"
(definition (rate_sample->interval_us rs) 1000)    ;; time for tp->delivered to incr "delivered"
(definition (rate_sample->delivered rs) 3)         ;; number of packets delivered over interval
(definition (rate_sample->is_app_limited rs) 0)    ;; is sample from packet with bubble in pipe?
(definition (rate_sample->prior_in_flight rs) 0)   ;; in flight before this ACK


;; Scale factor for rate in pkt/uSec unit to avoid truncation in bandwidth
;; estimation. The rate unit ~= (1500 bytes / 1 usec / 2^24) ~= 715 bps.
;; This handles bandwidths from 0.06pps (715bps) to 256Mpps (3Tbps) in a u32.
;; Since the minimum window is >=4 packets, the lower bound isn't
;; an issue. The upper bound isn't an issue with existing technologies.
(constant BW_SCALE 24)
(constant BW_UNIT (arithmetic-shift-left 1 BW_SCALE))

(constant BBR_SCALE 8) ;; scaling factor for fractions in BBR (e.g. gains)
(constant BBR_UNIT (arithmetic-shift-left 1 BBR_SCALE))

;; BBR has the following modes for deciding how fast to send:
(constant BBR_STARTUP   'BBR_STARTUP)    ;; ramp up sending rate rapidly to fill pipe
(constant BBR_DRAIN     'BBR_DRAIN)      ;; drain any queue created during startup
(constant BBR_PROBE_BW  'BBR_PROBE_BW)   ;; discover, share bw: pace around estimated bw
(constant BBR_PROBE_RTT 'BBR_PROBE_RTT)  ;; cut inflight to min to probe min_rtt

(constant CYCLE_LEN 8) ;; number of phases in a pacing gain cycle

;; Window length of bw filter (in rounds):
(constant bbr_bw_rtts (+ CYCLE_LEN 2))
;; Window length of min_rtt filter (in sec):
(constant bbr_min_rtt_win_sec 10)
;; Minimum time (in ms) spent at bbr_cwnd_min_target in BBR_PROBE_RTT mode:
(constant bbr_probe_rtt_mode_ms 200)
;; Skip TSO below the following bandwidth (bits/sec):
(constant bbr_min_tso_rate 1200000)

;; Pace at ~1% below estimated bw, on average, to reduce queue at bottleneck.
;; In order to help drive the network toward lower queues and low latency while
;; maintaining high utilization, the average pacing rate aims to be slightly
;; lower than the estimated bandwidth. This is an important aspect of the design.
(constant bbr_pacing_margin_percent 1)

;; We use a high_gain value of 2/ln(2) because it's the smallest pacing gain
;; that will allow a smoothly increasing pacing rate that will double each RTT
;; and send the same number of packets per RTT that an un-paced, slow-starting
;; Reno or CUBIC flow would:
(constant bbr_high_gain  (fxround (+ (/ (* BBR_UNIT 2885) 1000) 1)))
;; The pacing gain of 1/high_gain in BBR_DRAIN is calculated to typically drain
;; the queue created in BBR_STARTUP in a single round:
(constant bbr_drain_gain (fxround (/ (* BBR_UNIT 1000) 2885)))
;; The gain for deriving steady-state cwnd tolerates delayed/stretched ACKs:
(constant bbr_cwnd_gain  (fxround (* BBR_UNIT 2)))
;; The pacing_gain values for the PROBE_BW gain cycle, to discover/share bw:
(constant bbr_pacing_gain
  (vector
    (/ (* BBR_UNIT 5) 4)           ;; probe for more available bw
    (/ (* BBR_UNIT 3) 4)           ;; drain queue and/or yield bw to other flows
    BBR_UNIT BBR_UNIT BBR_UNIT     ;; cruise at 1.0*bw to utilize pipe,
    BBR_UNIT BBR_UNIT BBR_UNIT))   ;; without creating excess queue...
;; Randomize the starting gain cycling phase over N phases:
(constant bbr_cycle_rand 7)

;; Try to keep at least this many packets in flight, if things go smoothly. For
;; smooth functioning, a sliding window protocol ACKing every other packet
;; needs at least 4 packets in flight:
(constant bbr_cwnd_min_target 4)

;; To estimate if BBR_STARTUP mode (i.e. high_gain) has filled pipe...
;; If bw has increased significantly (1.25x), there may be more bw available:
(constant bbr_full_bw_thresh (fxround (/ (* BBR_UNIT 5) 4)))
;; But after 3 rounds w/o significant bw growth, estimate pipe is full:
(constant bbr_full_bw_cnt 3)

;; "long-term" ("LT") bandwidth estimator parameters...
;; The minimum number of rounds in an LT bw sampling interval:
(constant bbr_lt_intvl_min_rtts 4)
;; If lost/delivered ratio > 20%, interval is "lossy" and we may be policed:
(constant bbr_lt_loss_thresh 50)
;; If 2 intervals have a bw ratio <= 1/8, their bw is "consistent":
(constant bbr_lt_bw_ratio (fxround (/ BBR_UNIT 8)))
;; If 2 intervals have a bw diff <= 4 Kbit/sec their bw is "consistent":
(constant bbr_lt_bw_diff (fxround (/ 4000 8)))
;; If we estimate we're policed, use lt_bw for this many round trips:
(constant bbr_lt_bw_max_rtts 48)

;; Gain factor for adding extra_acked to target cwnd:
(constant bbr_extra_acked_gain BBR_UNIT)
;; Window length of extra_acked window.
(constant bbr_extra_acked_win_rtts 5)
;; Max allowed val for ack_epoch_acked, after which sampling epoch is reset
(constant bbr_ack_epoch_acked_reset_thresh (arithmetic-shift-left 1 20))
;; Time period for clamping cwnd increment due to ack aggregation
(constant bbr_extra_acked_max_us (* 100 1000))


(class UDP-BBR extends Object
  
  
  (slot min_rtt_us            <fx>     getter generate)   ;; min RTT in min_rtt_win_sec window : u32
  (slot min_rtt_stamp         <fx>     getter generate)   ;; timestamp of min_rtt_us : u32
  (slot probe_rtt_done_stamp  <fx>     getter generate)   ;; end time for BBR_PROBE_RTT mode : u32
  (slot bw_minmax             <object> getter generate)   ;; Max recent delivery rate in pkts/uS << 24 : struct minmax : minmax
  (slot rtt_cnt               <fx>     getter generate)   ;; count of packet-timed rounds elapsed : u32
  (slot next_rtt_delivered    <fx>     getter generate)   ;; scb->tx.delivered at end of round : u32
  (slot cycle_mstamp          <fx>     getter generate)   ;; time of this cycle phase start : u64
  (slot mode                  <symbol> getter generate)   ;; current bbr_mode in state machine : 3 bits
  (slot prev_ca_state         <fx>     getter generate)   ;; CA state on previous ACK : 3 bits
  (slot packet_conservation?  <bool>   getter generate)   ;; use packet conservation? : 1 bits
  (slot round_start?          <bool>   getter generate)   ;; start of packet-timed tx->ack round? : 1 bits
  (slot idle_restart?         <bool>   getter generate)   ;; restarting after idle? : 1 bits
  (slot probe_rtt_round_done? <bool>   getter generate)   ;; a BBR_PROBE_RTT round at 4 pkts? : 1 bits
  (slot lt_is_sampling?       <bool>   getter generate)   ;; taking long-term ("LT") samples now? : 1 bits
  (slot lt_rtt_cnt            <fx>     getter generate)   ;; round trips in long-term interval : 7 bits
  (slot lt_use_bw?            <bool>   getter generate)   ;; use lt_bw as our bw estimate? : 1 bits
  (slot lt_bw                 <fx>     getter generate)   ;; LT est delivery rate in pkts/uS << 24 : u32
  (slot lt_last_delivered     <fx>     getter generate)   ;; LT intvl start: tp->delivered : u32
  (slot lt_last_stamp         <fx>     getter generate)   ;; LT intvl start: tp->delivered_mstamp : u32
  (slot lt_last_lost          <fx>     getter generate)   ;; LT intvl start: tp->lost : u32
  (slot pacing_gain           <fx>     getter generate)   ;; current gain for setting pacing rate : 10 bits
  (slot cwnd_gain             <fx>     getter generate)   ;; current gain for setting cwnd : 10 bits
  (slot full_bw_reached?      <bool>   getter generate)   ;; reached full bw in Startup? : 1 bits
  (slot full_bw_cnt           <fx>     getter generate)   ;; number of rounds without large bw gains : 2 bits
  (slot cycle_idx             <fx>     getter generate)   ;; current index in pacing_gain cycle array : 3 bits
  (slot has_seen_rtt?         <bool>   getter generate)   ;; have we seen an RTT sample yet? : 1 bits
  (slot prior_cwnd            <fx>     getter generate)   ;; prior cwnd upon entering loss recovery : u32
  (slot full_bw               <fx>     getter generate)   ;; recent bw, to estimate if pipe is full : u32
  ;; For tracking ACK aggregation:
  (slot ack_epoch_mstamp      <fx>     getter generate)   ;; start of ACK sampling epoch : u64
  (slot extra_acked           <vector> getter generate)   ;; max excess data ACKed in epoch : u16[2]
  (slot ack_epoch_acked       <fx>     getter generate)   ;; packets (S)ACKed in sampling epoch : 20 bits
  (slot extra_acked_win_rtts  <fx>     getter generate)   ;; age of extra_acked, in round trips : 5 bits
  (slot extra_acked_win_idx   <fx>     getter generate)   ;; current index in extra_acked array : 1 bits
  
  
  ;;  Return the windowed max recent bandwidth sample, in pkts/uS << BW_SCALE.
  (method (bbr_max_bw self) <fx>
    (minmax bw_minmax))
  
  
  ;;  Return the estimated bandwidth of the path, in pkts/uS << BW_SCALE.
  (method (bbr_bw self) <fx>
    (if lt_use_bw?
        lt_bw
      (bbr_max_bw self)))
  

  ;;  Return maximum extra acked in past k-2k round trips,
  ;;  where k = bbr_extra_acked_win_rtts.
  (method (bbr_extra_acked self) <fx>
    (max (vector-ref extra_acked 0)
         (vector-ref extra_acked 1)))
  

  ;;  Return rate in bytes per second, optionally with a gain.
  ;;  The order here is chosen carefully to avoid overflow of u64. This should
  ;;  work for input rates of up to 2.9Tbit/sec and gain of 2.89x.
  (method (bbr_rate_bytes_per_sec self rate <fx> gain <fx>) <fx>
    (let ((mss (tcp_sk->mss_cache)))
      (multiply! rate mss)
      (multiply! rate gain)
      (set! rate (arithmetic-shift-right rate BBR_SCALE))
      (multiply! rate (* (/ USEC_PER_SEC 100) (- 100 bbr_pacing_margin_percent)))
      (arithmetic-shift-right rate BW_SCALE)))

  
  ;;  Convert a BBR bw and gain factor to a pacing rate in bytes per second.
  (method (bbr_bw_to_pacing_rate self bw <fx> gain <fx>) <fx>
    (let ((rate bw))
      (set! rate (bbr_rate_bytes_per_sec self rate gain))
      (set! rate (min rate (sk->sk_max_pacing_rate)))
      rate))

  
  ;;  Initialize pacing rate to: high_gain * init_cwnd / RTT.
  (method (bbr_init_pacing_rate_from_rtt self)
    (let ((rtt_us (unspecified)))
      (cond ((> (tcp_sk->srtt_us) 0)   ;; any RTT sample yet?
             (set! rtt_us (max (arithmetic-shift (tcp_sk->srtt_us) (- 3)) 1))
             (set! has_seen_rtt? #t))
            (else          ;; no RTT sample yet
             (set! rtt_us USEC_PER_MSEC)))     ;; use nominal default RTT
      (let ((bw (* (tcp_sk->snd_cwnd) BW_UNIT)))
        (set! bw (do_div bw rtt_us))
        (set-sk->sk_pacing_rate (bbr_bw_to_pacing_rate self bw bbr_high_gain)))))
  
  
  ;;  Pace using current bw estimate and a gain factor.
  (method (bbr_set_pacing_rate self bw gain <fx>)
    (let ((rate (bbr_bw_to_pacing_rate self bw gain)))
      (when (unlikely (and (not has_seen_rtt?) (> (tcp_sk->srtt_us) 0)))
        (bbr_init_pacing_rate_from_rtt self))
      (when (or full_bw_reached? (> rate (sk->sk_pacing_rate)))
        (set-sk->sk_pacing_rate rate))))

  
  ;;  override sysctl_tcp_min_tso_segs
  (method public (bbr_min_tso_segs self) <fx>
    (if (< (sk->sk_pacing_rate) (arithmetic-shift bbr_min_tso_rate (- 3)))
        1
      2))
  

  (method (bbr_tso_segs_goal self) <fx>
    ;; Sort of tcp_tso_autosize() but ignoring
    ;; driver provided sk_gso_max_size.
    (let ((bytes (min (arithmetic-shift
                        (sk->sk_pacing_rate)
                        (- (READ_ONCE (sk->sk_pacing_shift))))
                      (- (- GSO_MAX_SIZE 1) MAX_TCP_HEADER))))
      (let ((segs (max (/ bytes (tcp_sk->mss_cache)) (bbr_min_tso_segs self))))
        (min segs #x7F))))
  

  ;;  Save "last known good" cwnd so we can restore it after losses or PROBE_RTT
  (method (bbr_save_cwnd self)
    (if (and (< prev_ca_state TCP_CA_Recovery)
             (neq? mode BBR_PROBE_RTT))
        ;; this cwnd is good enough
        (set! prior_cwnd (tcp_sk->snd_cwnd))
      ;; loss recovery or BBR_PROBE_RTT have temporarily cut cwnd
      (set! prior_cwnd (max prior_cwnd (tcp_sk->snd_cwnd)))))
  

  (method public (bbr_cwnd_event self event)
    (when (and (eq? event 'CA_EVENT_TX_START) (> (tcp_sk->app_limited) 0))
      (set! idle_restart? #t)
      (set! ack_epoch_mstamp (tcp_sk->tcp_mstamp))
      (set! ack_epoch_acked 0)
      ;; Avoid pointless buffer overflows: pace at est. bw if we don't
      ;; need more speed (we're restarting from idle and app-limited).
      (if (eq? mode BBR_PROBE_BW)
          (bbr_set_pacing_rate self (bbr_bw self) BBR_UNIT)
        (when (eq? mode BBR_PROBE_RTT)
          (bbr_check_probe_rtt_done self)))))
  

  ;;  Calculate bdp based on min RTT and the estimated bottleneck bandwidth:
  ;;
  ;;  bdp = ceil(bw * min_rtt * gain)
  ;;
  ;;  The key factor, gain, controls the amount of queue. While a small gain
  ;;  builds a smaller queue, it becomes more vulnerable to noise in RTT
  ;;  measurements (e.g., delayed ACKs or other ACK compression effects). This
  ;;  noise may cause BBR to under-estimate the rate.
  (method (bbr_bdp self bw <fx> gain <fx>)
    ;; If we've never had a valid RTT sample, cap cwnd at the initial
    ;; default. This should only happen when the connection is not using TCP
    ;; timestamps and has retransmitted all of the SYN/SYNACK/data packets
    ;; ACKed so far. In this case, an RTO can cut cwnd to 1, in which
    ;; case we need to slow-start up toward something safe: TCP_INIT_CWND.
    (if (unlikely (= min_rtt_us tilde0U))     ;; no valid RTT samples yet?
        TCP_INIT_CWND   ;; be safe: cap at default initial cwnd
      (let ((w (* bw min_rtt_us)))
        ;; Apply a gain to the given value, remove the BW_SCALE shift, and
        ;; round the value up to avoid a negative feedback loop.
        (let ((bdp (fxround (/ (- (+ (arithmetic-shift (* w gain) (- BBR_SCALE)) BW_UNIT) 1) BW_UNIT))))
          bdp))))
  

  ;;  To achieve full performance in high-speed paths, we budget enough cwnd to
  ;;  fit full-sized skbs in-flight on both end hosts to fully utilize the path:
  ;;    - one skb in sending host Qdisc,
  ;;    - one skb in sending host TSO/GSO engine
  ;;    - one skb being received by receiver host LRO/GRO/delayed-ACK engine
  ;;  Don't worry, at low rates (bbr_min_tso_rate) this won't bloat cwnd because
  ;;  in such cases tso_segs_goal is 1. The minimum cwnd is 4 packets,
  ;;  which allows 2 outstanding 2-packet sequences, to try to keep pipe
  ;;  full even with ACK-every-other-packet delayed ACKs.
  (method (bbr_quantization_budget self cwnd <fx>)
    ;; Allow enough full-sized skbs in flight to utilize end systems.
    (increase! cwnd (* 3 (bbr_tso_segs_goal self)))
    ;; Reduce delayed ACKs by rounding up cwnd to the next even number.
    (set! cwnd (bitwise-and (+ cwnd 1) tilde1U))
    ;; Ensure gain cycling gets inflight above BDP even for small BDPs.
    (when (and (eq? mode BBR_PROBE_BW) (= cycle_idx 0))
      (increase! cwnd 2))
     cwnd)
  
  
  ;;  Find inflight based on min RTT and the estimated bottleneck bandwidth.
  (method (bbr_inflight self bw <fx> gain <fx>)
    (let ((inflight (bbr_bdp self bw gain)))
      (set! inflight (bbr_quantization_budget self inflight))
      inflight))
  

  ;;  With pacing at lower layers, there's often less data "in the network" than
  ;;  "in flight". With TSQ and departure time pacing at lower layers (e.g. fq),
  ;;  we often have several skbs queued in the pacing layer with a pre-scheduled
  ;;  earliest departure time (EDT). BBR adapts its pacing rate based on the
  ;;  inflight level that it estimates has already been "baked in" by previous
  ;;  departure time decisions. We calculate a rough estimate of the number of our
  ;;  packets that might be in the network at the earliest departure time for the
  ;;  next skb scheduled:
  ;;    in_network_at_edt = inflight_at_edt - (EDT - now) * bw
  ;;  If we're increasing inflight, then we want to know if the transmit of the
  ;;  EDT skb will push inflight above the target, so inflight_at_edt includes
  ;;  bbr_tso_segs_goal() from the skb departing at EDT. If decreasing inflight,
  ;;  then estimate if inflight will sink too low just before the EDT transmit.
  (method (bbr_packets_in_net_at_edt self inflight_now <fx>)
    (let* ((now_ns (tcp_sk->tcp_clock_cache))
           (edt_ns (max (tcp_sk->tcp_wstamp_ns) now_ns))
           (interval_us (div_u64 (- edt_ns now_ns) NSEC_PER_USEC))
           (interval_delivered (arithmetic-shift (* (bbr_bw self) interval_us) (- BW_SCALE)))
           (inflight_at_edt inflight_now))
      (when (> pacing_gain BBR_UNIT)                  ;; increasing inflight
        (increase! inflight_at_edt (bbr_tso_segs_goal self)))  ;; include EDT skb
      (if (>= interval_delivered inflight_at_edt)
          0
        (- inflight_at_edt interval_delivered))))
  

  ;;  Find the cwnd increment based on estimate of ack aggregation
  (method (bbr_ack_aggregation_cwnd self)
    (let ((max_aggr_cwnd 0)
          (aggr_cwnd 0))
      (when (and (> bbr_extra_acked_gain 0) full_bw_reached?)
        (set! max_aggr_cwnd (/ (* (bbr_bw self) bbr_extra_acked_max_us) BW_UNIT))
        (set! aggr_cwnd
              (arithmetic-shift
                (* bbr_extra_acked_gain (bbr_extra_acked self))
                (- BBR_SCALE)))
        (set! aggr_cwnd (min aggr_cwnd max_aggr_cwnd)))
      aggr_cwnd))
  

  ;;  An optimization in BBR to reduce losses: On the first round of recovery, we
  ;;  follow the packet conservation principle: send P packets per P packets acked.
  ;;  After that, we slow-start and send at most 2*P packets per P packets acked.
  ;;  After recovery finishes, or upon undo, we restore the cwnd we had when
  ;;  recovery started (capped by the target cwnd based on estimated BDP).
  (method (bbr_set_cwnd_to_recover_or_restore self rs acked <fx>)
    (let ((prev_state prev_ca_state)
          (state (inet_csk->icsk_ca_state))
          (cwnd (tcp_sk->snd_cwnd)))
      ;; An ACK for P pkts should release at most 2*P packets. We do this
      ;; in two steps. First, here we deduct the number of lost packets.
      ;; Then, in bbr_set_cwnd() we slow start up toward the target cwnd.
      (when (> (rate_sample->losses rs) 0)
        (set! cwnd (max (- cwnd (rate_sample->losses rs)) 1)))
      
      (if (and (= state TCP_CA_Recovery) (/= prev_state TCP_CA_Recovery))
          (begin
            ;; Starting 1st round of Recovery, so do packet conservation.
            (set! packet_conservation? #t)
            (set! next_rtt_delivered (tcp_sk->delivered))  ;; start round now
            ;; Cut unused cwnd from app behavior, TSQ, or TSO deferral:
            (set! cwnd (+ (tcp_packets_in_flight) acked)))
        (when (and (>= prev_state TCP_CA_Recovery) (< state TCP_CA_Recovery))
          ;; Exiting loss recovery; restore cwnd saved before recovery.
          (set! cwnd (max cwnd prior_cwnd))
          (set! packet_conservation? #f)))
      (set! prev_ca_state state)
      
      (cond (packet_conservation?
             (values (max cwnd (+ (tcp_packets_in_flight) acked))
                     #t))    ;; yes, using packet conservation
            (else
             (values cwnd
                     #f)))))
  

  ;;  Slow-start up toward target cwnd (if bw estimate is growing, or packet loss
  ;;  has drawn us down below target), or snap down to target if we're above it.
  (method (bbr_set_cwnd self rs acked <fx> bw <fx> gain <fx>)
    (let ((cwnd (tcp_sk->snd_cwnd))
          (target_cwnd 0))
      (define (done)
        (set-tcp_sk->snd_cwnd (min cwnd (tcp_sk->snd_cwnd_clamp)))    ;; apply global cap
        (when (eq? mode BBR_PROBE_RTT)  ;; drain queue, refresh min_rtt
          (set-tcp_sk->snd_cwnd (min (tcp_sk->snd_cwnd) bbr_cwnd_min_target))))
      
      (if (= acked 0)
          (done)  ;; no packet fully ACKed; just apply caps
        (receive (cwnd using_packet_conservation?) (bbr_set_cwnd_to_recover_or_restore self rs acked)
          (if using_packet_conservation?
              (done)
            (set! target_cwnd (bbr_bdp self bw gain))
            
            ;; Increment the cwnd to account for excess ACKed data that seems
            ;; due to aggregation (of data and/or ACKs) visible in the ACK stream.
            (increase! target_cwnd (bbr_ack_aggregation_cwnd self))
            (set! target_cwnd (bbr_quantization_budget self target_cwnd))
            
            ;; If we're below target cwnd, slow start cwnd toward target cwnd.
            (if full_bw_reached?  ;; only cut cwnd if we filled the pipe
                (set! cwnd (min (+ cwnd acked) target_cwnd))
              (when (or (< cwnd target_cwnd) (< (tcp_sk->delivered) TCP_INIT_CWND))
                (set! cwnd (+ cwnd acked))))
            (set! cwnd (max cwnd bbr_cwnd_min_target)))))))
  

  ;;  End cycle phase if it's time and/or we hit the phase's in-flight target.
  (method (bbr_is_next_cycle_phase self rs)
    (let ((is_full_length
            (> (tcp_stamp_us_delta (tcp_sk->delivered_mstamp) cycle_mstamp)
               min_rtt_us)))
      ;; The pacing_gain of 1.0 paces at the estimated bw to try to fully
      ;; use the pipe without increasing the queue.
      (if (= pacing_gain BBR_UNIT)
          is_full_length        ;; just use wall clock time
        (let ((inflight (bbr_packets_in_net_at_edt self (rate_sample->prior_in_flight rs)))
              (bw (bbr_max_bw self)))
          ;; A pacing_gain > 1.0 probes for bw by trying to raise inflight to at
          ;; least pacing_gain*BDP; this may take more than min_rtt if min_rtt is
          ;; small (e.g. on a LAN). We do not persist if packets are lost, since
          ;; a path with small buffers may not hold that much.
          (if (> pacing_gain BBR_UNIT)
              (and is_full_length
                   (or (rate_sample->losses rs)  ;; perhaps pacing_gain*BDP won't fit
                       (>= inflight (bbr_inflight self bw pacing_gain))))
            ;; A pacing_gain < 1.0 tries to drain extra queue we added if bw
            ;; probing didn't find more bw. If inflight falls to match BDP then we
            ;; estimate queue is drained; persisting would underutilize the pipe.
            (or is_full_length
                (<= inflight (bbr_inflight self bw BBR_UNIT))))))))
  

  (method (bbr_advance_cycle_phase self)
    (set! cycle_idx (bitwise-and (+ cycle_idx 1) (- CYCLE_LEN 1)))
    (set! cycle_mstamp (tcp_sk->delivered_mstamp)))
  

  ;;  Gain cycling: cycle pacing gain to converge to fair share of available bw.
  (method (bbr_update_cycle_phase self rs)
    (when (and (eq? mode BBR_PROBE_BW) (bbr_is_next_cycle_phase self rs))
      (bbr_advance_cycle_phase self)))
  
  
  (method (bbr_set_mode self m)
    (show 'mode '=> m)
    (set! mode m))
  

  (method (bbr_reset_startup_mode self)
    (bbr_set_mode self BBR_STARTUP))
  

  (method (bbr_reset_probe_bw_mode self)
    (bbr_set_mode self BBR_PROBE_BW)
    (set! cycle_idx (- (- CYCLE_LEN 1) (prandom_u32_max bbr_cycle_rand)))
    (bbr_advance_cycle_phase self))    ;; flip to next phase of gain cycle
  

  (method (bbr_reset_mode self)
    (if (not full_bw_reached?)
        (bbr_reset_startup_mode self)
      (bbr_reset_probe_bw_mode self)))
  

  ;;  Start a new long-term sampling interval.
  (method (bbr_reset_lt_bw_sampling_interval self)
    (set! lt_last_stamp (div_u64 (tcp_sk->delivered_mstamp) USEC_PER_MSEC))
    (set! lt_last_delivered (tcp_sk->delivered))
    (set! lt_last_lost (tcp_sk->lost))
    (set! lt_rtt_cnt 0))
  

  ;;  Completely reset long-term bandwidth sampling.
  (method (bbr_reset_lt_bw_sampling self)
    (set! lt_bw 0)
    (set! lt_use_bw? #f)
    (set! lt_is_sampling? #f)
    (bbr_reset_lt_bw_sampling_interval self))
  

  ;;  Long-term bw sampling interval is done. Estimate whether we're policed.
  (method (bbr_lt_bw_interval_done self bw <fx>)
    (continuation-capture
      (lambda (return)
        (when (> lt_bw 0)  ;; do we have bw from a previous interval?
          ;; Is new bw close to the lt_bw from the previous interval?
          (let ((diff (abs (- bw lt_bw))))
            (when (or (<= (* diff BBR_UNIT) (* bbr_lt_bw_ratio lt_bw))
                      (<= (bbr_rate_bytes_per_sec self diff BBR_UNIT) bbr_lt_bw_diff))
              ;; All criteria are met; estimate we're policed.
              (set! lt_bw (arithmetic-shift (+ bw lt_bw) (- 1)))  ;; avg 2 intvls
              (set! lt_use_bw? #t)
              (set! pacing_gain BBR_UNIT)  ;; try to avoid drops
              (set! lt_rtt_cnt 0)
              (continuation-return return))))
        
        (set! lt_bw bw)
        (bbr_reset_lt_bw_sampling_interval self))))
  

  ;;  Token-bucket traffic policers are common (see "An Internet-Wide Analysis of
  ;;  Traffic Policing", SIGCOMM 2016). BBR detects token-bucket policers and
  ;;  explicitly models their policed rate, to reduce unnecessary losses. We
  ;;  estimate that we're policed if we see 2 consecutive sampling intervals with
  ;;  consistent throughput and high packet loss. If we think we're being policed,
  ;;  set lt_bw to the "long-term" average delivery rate from those 2 intervals.
  (method (bbr_lt_bw_sampling self rs)
    (continuation-capture
      (lambda (return)
        (when lt_use_bw?    ;; already using long-term rate, lt_bw?
          (when (and (eq? mode BBR_PROBE_BW)
                     round_start?
                     (begin
                       (increase! lt_rtt_cnt)
                       (>= lt_rtt_cnt bbr_lt_bw_max_rtts)))
            (bbr_reset_lt_bw_sampling self)    ;; stop using lt_bw
            (bbr_reset_probe_bw_mode self))  ;; restart gain cycling
          (continuation-return return))
        
        ;; Wait for the first loss before sampling, to let the policer exhaust
        ;; its tokens and estimate the steady-state rate allowed by the policer.
        ;; Starting samples earlier includes bursts that over-estimate the bw.
        (when (not lt_is_sampling?)
          (when (= (rate_sample->losses rs) 0)
            (continuation-return return))
          (bbr_reset_lt_bw_sampling_interval self)
          (set! lt_is_sampling? #t))
        
        ;; To avoid underestimates, reset sampling if we run out of data.
        (when (rate_sample->is_app_limited rs)
          (bbr_reset_lt_bw_sampling self)
          (continuation-return return))
        
        (when round_start?
          (increase! lt_rtt_cnt))    ;; count round trips in this interval
        (when (< lt_rtt_cnt bbr_lt_intvl_min_rtts)
          (continuation-return return))        ;; sampling interval needs to be longer
        (when (> lt_rtt_cnt (* 4 bbr_lt_intvl_min_rtts))
          (bbr_reset_lt_bw_sampling self)  ;; interval is too long
          (continuation-return return))
        
        ;; End sampling interval when a packet is lost, so we estimate the
        ;; policer tokens were exhausted. Stopping the sampling before the
        ;; tokens are exhausted under-estimates the policed rate.
        (when (= (rate_sample->losses rs) 0)
          (continuation-return return))
        
        ;; Calculate packets lost and delivered in sampling interval.
        (let ((lost (- (tcp_sk->lost) lt_last_lost))
              (delivered (- (tcp_sk->delivered) lt_last_delivered)))
          ;; Is loss rate (lost/delivered) >= lt_loss_thresh? If not, wait.
          (when (or (= delivered 0)
                    (< (arithmetic-shift lost BBR_SCALE)
                       (* bbr_lt_loss_thresh delivered)))
            (continuation-return return))
          
          ;; Find average delivery rate in this sampling interval.
          (let ((t (- (div_u64 (tcp_sk->delivered_mstamp) USEC_PER_MSEC) lt_last_stamp)))
            (when (< t 1)
              (continuation-return return))        ;; interval is less than one ms, so wait
            ;; Check if can multiply without overflow
            (when (>= t (/ tilde0U USEC_PER_MSEC))
              (bbr_reset_lt_bw_sampling self)  ;; interval too long; reset
              (continuation-return return))
            (multiply! t USEC_PER_MSEC)
            (let ((bw (* delivered BW_UNIT)))
              (set! bw (do_div bw t))
              (bbr_lt_bw_interval_done self bw)))))))
  

  ;;  Estimate the bandwidth based on how fast packets are delivered
  (method (bbr_update_bw self rs)
    (continuation-capture
      (lambda (return)
        (set! round_start? #f)
        (when (or (< (rate_sample->delivered rs) 0) (<= (rate_sample->interval_us rs) 0))
          (continuation-return return)) ;; Not a valid observation
        
        ;; See if we've reached the next RTT
        (when (not (before (rate_sample->prior_delivered rs) next_rtt_delivered))
          (set! next_rtt_delivered (tcp_sk->delivered))
          (increase! rtt_cnt)
          (set! round_start? #t)
          (set! packet_conservation? #f))
        
        (bbr_lt_bw_sampling self rs)
        
        ;; Divide delivered by the interval to find a (lower bound) bottleneck
        ;; bandwidth sample. Delivered is in packets and interval_us in uS and
        ;; ratio will be <<1 for most connections. So delivered is first scaled.
        (let ((bw (div64_long (* (rate_sample->delivered rs) BW_UNIT) (rate_sample->interval_us rs))))
          
          ;; If this sample is application-limited, it is likely to have a very
          ;; low delivered count that represents application behavior rather than
          ;; the available network rate. Such a sample could drag down estimated
          ;; bw, causing needless slow-down. Thus, to continue to send at the
          ;; last measured network rate, we filter out app-limited samples unless
          ;; they describe the path bw at least as well as our bw model.
          ;;
          ;; So the goal during app-limited phase is to proceed with the best
          ;; network rate no matter how long. We automatically leave this
          ;; phase when app writes faster than the network can deliver :)
          (when (or (not (rate_sample->is_app_limited rs))
                    (>= bw (bbr_max_bw self)))
            ;; Incorporate new sample into our max bw filter.
            (running-max bw_minmax bbr_bw_rtts rtt_cnt bw))))))
  

  ;;  Estimates the windowed max degree of ack aggregation.
  ;;  This is used to provision extra in-flight data to keep sending during
  ;;  inter-ACK silences.
  ;;
  ;;  Degree of ack aggregation is estimated as extra data acked beyond expected.
  ;;
  ;;  max_extra_acked = "maximum recent excess data ACKed beyond max_bw * interval"
  ;;  cwnd += max_extra_acked
  ;;
  ;;  Max extra_acked is clamped by cwnd and bw * bbr_extra_acked_max_us (100 ms).
  ;;  Max filter is an approximate sliding window of 5-10 (packet timed) round
  ;;  trips.
  (method (bbr_update_ack_aggregation self rs)
    (continuation-capture
      (lambda (return)
        (when (or (= bbr_extra_acked_gain 0)
                  (<= (rate_sample->acked_sacked rs) 0)
                  (< (rate_sample->delivered rs) 0)
                  (<= (rate_sample->interval_us rs) 0))
          (continuation-return return))
        
        (when round_start?
          (set! extra_acked_win_rtts
                (min #x1F (+ extra_acked_win_rtts 1)))
          (when (>= extra_acked_win_rtts bbr_extra_acked_win_rtts)
            (set! extra_acked_win_rtts 0)
            (set! extra_acked_win_idx (if (/= extra_acked_win_idx 0) 0 1))
            (vector-set! extra_acked extra_acked_win_idx 0)))
        
        ;; Compute how many packets we expected to be delivered over epoch.
        (let* ((epoch_us (tcp_stamp_us_delta (tcp_sk->delivered_mstamp) ack_epoch_mstamp))
               (expected_acked (/ (* (bbr_bw self) epoch_us) BW_UNIT)))
          
          ;; Reset the aggregation epoch if ACK rate is below expected rate or
          ;; significantly large no. of ack received since epoch (potentially
          ;; quite old epoch).
          (when (or (<= ack_epoch_acked expected_acked)
                    (>= (+ ack_epoch_acked (rate_sample->acked_sacked rs))
                        bbr_ack_epoch_acked_reset_thresh))
            (set! ack_epoch_acked 0)
            (set! ack_epoch_mstamp (tcp_sk->delivered_mstamp))
            (set! expected_acked 0))
          
          ;; Compute excess data delivered, beyond what was expected.
          (set! ack_epoch_acked (min #xFFFFF (+ ack_epoch_acked (rate_sample->acked_sacked rs))))
          (set! extra_acked (- ack_epoch_acked expected_acked))
          (set! extra_acked (min extra_acked (tcp_sk->snd_cwnd)))
          (when (> extra_acked
                   (vector-ref extra_acked extra_acked_win_idx))
            (vector-set! extra_acked extra_acked_win_idx extra_acked))))))
  

  ;;  Estimate when the pipe is full, using the change in delivery rate: BBR
  ;;  estimates that STARTUP filled the pipe if the estimated bw hasn't changed by
  ;;  at least bbr_full_bw_thresh (25%) after bbr_full_bw_cnt (3) non-app-limited
  ;;  rounds. Why 3 rounds: 1: rwin autotuning grows the rwin, 2: we fill the
  ;;  higher rwin, 3: we get higher delivery rate samples. Or transient
  ;;  cross-traffic or radio noise can go away. CUBIC Hystart shares a similar
  ;;  design goal, but uses delay and inter-ACK spacing instead of bandwidth.
  (method (bbr_check_full_bw_reached self rs)
    (continuation-capture
      (lambda (return)
        (when (or full_bw_reached?
                  (not round_start?)
                  (rate_sample->is_app_limited rs))
          (continuation-return return))
        
        (let ((bw_thresh (arithmetic-shift (* full_bw bbr_full_bw_thresh) (- BBR_SCALE))))
          (when (>= (bbr_max_bw self) bw_thresh)
            (set! full_bw (bbr_max_bw self))
            (set! full_bw_cnt 0)
            (continuation-return return))
          (increase! full_bw_cnt)
          (set! full_bw_reached? (>= full_bw_cnt bbr_full_bw_cnt))))))
  
  
  ;;  If pipe is probably full, drain the queue and then enter steady-state.
  (method (bbr_check_drain self rs)
    (when (and (eq? mode BBR_STARTUP) full_bw_reached?)
      (bbr_set_mode self BBR_DRAIN)    ;; drain queue we created
      (set-tcp_sk->snd_ssthresh (bbr_inflight self (bbr_max_bw self) BBR_UNIT)))
    ;; fall through to check if in-flight is already small:
    (when (and (eq? mode BBR_DRAIN)
               (<= (bbr_packets_in_net_at_edt self (tcp_packets_in_flight))
                   (bbr_inflight self (bbr_max_bw self) BBR_UNIT)))
      ;; we estimate queue is drained
      (bbr_reset_probe_bw_mode self)))

  
  (method (bbr_check_probe_rtt_done self)
    (when (and (> probe_rtt_done_stamp 0)
               (after (tcp_jiffies32) probe_rtt_done_stamp))
      (set! min_rtt_stamp (tcp_jiffies32))  ;; wait a while until PROBE_RTT
      (set-tcp_sk->snd_cwnd (max (tcp_sk->snd_cwnd) prior_cwnd))
      (bbr_reset_mode self)))
  

  ;;  The goal of PROBE_RTT mode is to have BBR flows cooperatively and
  ;;  periodically drain the bottleneck queue, to converge to measure the true
  ;;  min_rtt (unloaded propagation delay). This allows the flows to keep queues
  ;;  small (reducing queuing delay and packet loss) and achieve fairness among
  ;;  BBR flows.
  ;;
  ;;  The min_rtt filter window is 10 seconds. When the min_rtt estimate expires,
  ;;  we enter PROBE_RTT mode and cap the cwnd at bbr_cwnd_min_target=4 packets.
  ;;  After at least bbr_probe_rtt_mode_ms=200ms and at least one packet-timed
  ;;  round trip elapsed with that flight size <= 4, we leave PROBE_RTT mode and
  ;;  re-enter the previous mode. BBR uses 200ms to approximately bound the
  ;;  performance penalty of PROBE_RTT's cwnd capping to roughly 2% (200ms/10s).
  ;;
  ;;  Note that flows need only pay 2% if they are busy sending over the last 10
  ;;  seconds. Interactive applications (e.g., Web, RPCs, video chunks) often have
  ;;  natural silences or low-rate periods within 10 seconds where the rate is low
  ;;  enough for long enough to drain its queue in the bottleneck. We pick up
  ;;  these min RTT measurements opportunistically with our min_rtt filter. :-)
  (method (bbr_update_min_rtt self rs)
    ;; Track min RTT seen in the min_rtt_win_sec filter window:
    (let ((filter_expired?
            (after (tcp_jiffies32)
                   (+ min_rtt_stamp (* bbr_min_rtt_win_sec HZ)))))
      (when (and (>= (rate_sample->rtt_us rs) 0)
                 (or (< (rate_sample->rtt_us rs) min_rtt_us)
                     (and filter_expired? (not (rate_sample->is_ack_delayed rs)))))
        (set! min_rtt_us (rate_sample->rtt_us rs))
        (set! min_rtt_stamp (tcp_jiffies32)))
      
      (when (and (> bbr_probe_rtt_mode_ms 0)
                 filter_expired?
                 (not idle_restart?)
                 (neq? mode BBR_PROBE_RTT))
        (bbr_set_mode self BBR_PROBE_RTT)  ;; dip, drain queue
        (bbr_save_cwnd self)  ;; note cwnd so we can restore it
        (set! probe_rtt_done_stamp 0))
      
      (when (eq? mode BBR_PROBE_RTT)
        ;; Ignore low rate samples during this mode.
        (set-tcp_sk->app_limited (let ((test-result (+ (tcp_sk->delivered) (tcp_packets_in_flight))))
                                   (if (> test-result 0) test-result 1)))
        ;; Maintain min packets in flight for max(200 ms, 1 round).
        (if (and (= probe_rtt_done_stamp 0)
                 (<= (tcp_packets_in_flight) bbr_cwnd_min_target))
            (begin
              (set! probe_rtt_done_stamp
                    (+ (tcp_jiffies32) (msecs_to_jiffies bbr_probe_rtt_mode_ms)))
              (set! probe_rtt_round_done? #f)
              (set! next_rtt_delivered (tcp_sk->delivered)))
          (when (> probe_rtt_done_stamp 0)
            (when round_start?
              (set! probe_rtt_round_done? #t))
            (when probe_rtt_round_done?
              (bbr_check_probe_rtt_done self)))))
      
      ;; Restart after idle ends only once we process a new S/ACK for data
      (when (> (rate_sample->delivered rs) 0)
        (set! idle_restart? #f))))
  

  (method (bbr_update_gains self)
    (case mode
      ((BBR_STARTUP)
       (set! pacing_gain bbr_high_gain)
       (set! cwnd_gain bbr_high_gain))
      ((BBR_DRAIN)
       (set! pacing_gain bbr_drain_gain)  ;; slow, to drain
       (set! cwnd_gain bbr_high_gain))    ;; keep cwnd
      ((BBR_PROBE_BW)
       (set! pacing_gain (if lt_use_bw?
                             BBR_UNIT
                           (vector-ref bbr_pacing_gain cycle_idx)))
       (set! cwnd_gain bbr_cwnd_gain))
      ((BBR_PROBE_RTT)
       (set! pacing_gain BBR_UNIT)
       (set! cwnd_gain BBR_UNIT))
      (else
       (error "BBR bad mode: {a}" mode))))

  
  (method (bbr_update_model self rs)
    (bbr_update_bw self rs)
    (bbr_update_ack_aggregation self rs)
    (bbr_update_cycle_phase self rs)
    (bbr_check_full_bw_reached self rs)
    (bbr_check_drain self rs)
    (bbr_update_min_rtt self rs)
    (bbr_update_gains self))
  

  (method public (bbr_main self rs)
    (bbr_update_model self rs)
    (let ((bw (bbr_bw self)))
      (bbr_set_pacing_rate self bw pacing_gain)
      (bbr_set_cwnd self rs (rate_sample->acked_sacked rs) bw cwnd_gain)))
  

  (method public (bbr_init self)
    (set! bw_minmax (new Windowed-MinMax))
    (set! prior_cwnd 0)
    (set-tcp_sk->snd_ssthresh TCP_INFINITE_SSTHRESH)
    (set! rtt_cnt 0)
    (set! next_rtt_delivered (tcp_sk->delivered))
    (set! prev_ca_state TCP_CA_Open)
    (set! packet_conservation? #f)

    (set! probe_rtt_done_stamp 0)
    (set! probe_rtt_round_done? #f)
    (set! min_rtt_us (tcp_min_rtt))
    (set! min_rtt_stamp (tcp_jiffies32))

    (reset bw_minmax rtt_cnt 0)  ;; init max bw to 0

    (set! has_seen_rtt? #f)
    (bbr_init_pacing_rate_from_rtt self)

    (set! round_start? #f)
    (set! idle_restart? #f)
    (set! full_bw_reached? #f)
    (set! full_bw 0)
    (set! full_bw_cnt 0)
    (set! cycle_mstamp 0)
    (set! cycle_idx 0)
    (bbr_reset_lt_bw_sampling self)
    (bbr_reset_startup_mode self)

    (set! ack_epoch_mstamp (tcp_sk->tcp_mstamp))
    (set! ack_epoch_acked 0)
    (set! extra_acked_win_rtts 0)
    (set! extra_acked_win_idx 0)
    (set! extra_acked (vector 0 0))

    @todo-dont-think-this-is-needed
    (cmpxchg (sk->sk_pacing_status) SK_PACING_NONE SK_PACING_NEEDED))
  

  (method public (bbr_sndbuf_expand self)
    ;; Provision 3 * cwnd since BBR may slow-start even during recovery.
    3)
  

  ;;  In theory BBR does not need to undo the cwnd since it does not
  ;;  always reduce cwnd on losses (see bbr_main()). Keep it for now.
  (method public (bbr_undo_cwnd self)
    (set! full_bw 0)   ;; spurious slow-down; reset full pipe detection
    (set! full_bw_cnt 0)
    (bbr_reset_lt_bw_sampling self)
    (tcp_sk->snd_cwnd))
  

  ;;  Entering loss recovery, so save cwnd for when we exit or undo recovery.
  (method public (bbr_ssthresh self)
    (bbr_save_cwnd self)
    (tcp_sk->snd_ssthresh))
  

  (method public (bbr_set_state self new_state)
#|
    if (new_state == TCP_CA_Loss) {
        struct rate_sample rs = { .losses = 1 };

        bbr->prev_ca_state = TCP_CA_Loss;
        bbr->full_bw = 0;
        bbr->round_start? = #t;    ;; treat RTO like end of a round
        bbr_lt_bw_sampling(self, &rs);
    }
|#
  )
  
  
  ;; bbr_init
  ;; bbr_main
  ;; bbr_sndbuf_expand
  ;; bbr_undo_cwnd
  ;; bbr_cwnd_event
  ;; bbr_ssthresh
  ;; bbr_min_tso_segs
  
  ;; initialize private data (optional)
  ;; .init		= bbr_init
  ;; call when packets are delivered to update cwnd and pacing rate,
  ;; after all the ca_state processing. (optional)
  ;; .cong_control	= bbr_main
  ;; returns the multiplier used in tcp_sndbuf_expand (optional)
  ;; .sndbuf_expand	= bbr_sndbuf_expand
  ;; new value of cwnd after loss (required)
  ;; .undo_cwnd	= bbr_undo_cwnd
  ;; call when cwnd event occurs (optional)
  ;; .cwnd_event	= bbr_cwnd_event
  ;; return slow start threshold (required)
  ;; .ssthresh	= bbr_ssthresh
  ;; override sysctl_tcp_min_tso_segs
  ;; .min_tso_segs	= bbr_min_tso_segs
  ;; get info for inet_diag (optional)
  ;; .get_info	= bbr_get_info
  ;; call before changing ca_state (optional)
  ;; .set_state	= bbr_set_state
))
